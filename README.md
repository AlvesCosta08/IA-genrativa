ğŸ“„ Dr. Legal & Advogados â€“ Assistente JurÃ­dico Virtual
Sistema completo de atendimento jurÃ­dico automatizado com IA local, chatbot inteligente e conversÃ£o direta via WhatsApp.
Desenvolvido com Flask, Ollama e Docker para garantir privacidade, desempenho e escalabilidade. 

ğŸŒŸ VisÃ£o Geral
O Dr. Legal & Advogados Ã© uma soluÃ§Ã£o moderna e eficaz para escritÃ³rios de advocacia que desejam:

Oferecer atendimento 24h com um assistente jurÃ­dico virtual inteligente.
Entender dÃºvidas em linguagem natural.
Classificar automaticamente a Ã¡rea do direito mais adequada.
Responder com empatia, clareza e tom humano.
Gerar conversÃµes por meio de CTAs personalizados e direcionamento direto ao WhatsApp.
Todo o processamento de inteligÃªncia artificial Ã© feito localmente com Ollama, sem dependÃªncia de APIs externas, garantindo:

âœ… Privacidade total
âœ… Conformidade com a LGPD
âœ… Baixa latÃªncia
âœ… OperaÃ§Ã£o offline (sem envio de dados)

ğŸ”§ Arquitetura do Sistema
O sistema Ã© composto por dois serviÃ§os containerizados, orquestrados com Docker Compose:

ollama
Ubuntu + Ollama
Executa modelos de IA localmente (ex:
tinyllama
)
web
Python + Flask
Backend, frontend e API de comunicaÃ§Ã£o

A arquitetura permite fÃ¡cil implantaÃ§Ã£o, manutenÃ§Ã£o e escalabilidade.

ğŸ“¦ Estrutura de Projetos

Â´Â´Â´
dr-legal-advogados/
â”‚
â”œâ”€â”€ ollama-container/               # ServiÃ§o de IA local
â”‚   â”œâ”€â”€ Dockerfile                  # Imagem base: Ubuntu 22.04 + Ollama
â”‚   â””â”€â”€ start.sh                    # InicializaÃ§Ã£o e download do modelo
â”‚
â”œâ”€â”€ web-container/                  # ServiÃ§o web (Flask)
â”‚   â”œâ”€â”€ Dockerfile                  # Imagem: Python 3.10-slim
â”‚   â”œâ”€â”€ app.py                      # Backend com lÃ³gica de IA e CTA
â”‚   â”œâ”€â”€ requirements.txt            # DependÃªncias: Flask, requests
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html              # Frontend responsivo com chatbot
â”‚
â”œâ”€â”€ docker-compose.yml              # OrquestraÃ§Ã£o dos serviÃ§os
â””â”€â”€ README.md                       # Este arquivo
âš™ï¸ ServiÃ§o 1: ollama-container (IA Local)
Dockerfile



FROM ubuntu:22.04

# Evita interaÃ§Ãµes durante instalaÃ§Ã£o de pacotes
ENV DEBIAN_FRONTEND=noninteractive

# Instala dependÃªncias bÃ¡sicas
RUN apt update && \
    apt install -y curl wget sudo && \
    rm -rf /var/lib/apt/lists/*

# Instala o Ollama via script oficial
RUN curl -fsSL https://ollama.com/install.sh | sh

# Cria usuÃ¡rio dedicado
RUN useradd -m -s /bin/bash ollama && \
    usermod -aG ollama ollama && \
    echo "ollama ALL=(ALL) NOPASSWD:ALL" >> /etc/sudoers

# Permite acesso externo Ã  API
ENV OLLAMA_HOST=0.0.0.0

# DiretÃ³rio persistente para modelos
VOLUME ["/root/.ollama"]

# Porta da API
EXPOSE 11434

# Script de inicializaÃ§Ã£o
COPY start.sh /start.sh
RUN chmod +x /start.sh

# Inicia o serviÃ§o
CMD ["/start.sh"]
start.sh
bash



#!/bin/bash
echo "ğŸš€ Iniciando Ollama..."
ollama serve &

sleep 10

echo "ğŸ“¥ Baixando modelo leve: tinyllama:1.1b"
ollama pull tinyllama:1.1b

echo "âœ… Modelo pronto!"
wait
ğŸ” Funcionalidades
Instala e configura o Ollama em ambiente Ubuntu.
Inicia o servidor ollama serve em segundo plano.
Baixa automaticamente o modelo tinyllama:1.1b para inferÃªncia local.
ExpÃµe a API em http://localhost:11434.
Persiste modelos com volume Docker (ollama_data), evitando downloads repetidos.
CompatÃ­vel com GPU (NVIDIA/AMD) â€” o script oficial instala drivers se necessÃ¡rio.
ğŸŒ ServiÃ§o 2: web-container (Backend + Frontend)
Dockerfile
Dockerfile



FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 5000

CMD ["python", "app.py"]
requirements.txt
txt


flask
requests
app.py â€“ Backend Flask
O backend implementa uma camada inteligente de triagem jurÃ­dica, com:

1. DetecÃ§Ã£o de IntenÃ§Ã£o
SaudaÃ§Ãµes, despedidas, contato, horÃ¡rios, honorÃ¡rios.
Temas comuns: "divÃ³rcio", "acidente", "golpe no PIX", "aposentadoria".
2. ClassificaÃ§Ã£o por Ãrea do Direito
Utiliza dicionÃ¡rio de palavras-chave para mapear perguntas a especialidades:

python



âŒ„
PALAVRAS_JURIDICAS = {
    "Direito de FamÃ­lia": ["divÃ³rcio", "guarda", "pensÃ£o", ...],
    "Direito Trabalhista": ["demitido", "horas extras", "FGTS", ...],
    "Direito PrevidenciÃ¡rio": ["aposentadoria", "auxÃ­lio-doenÃ§a", ...],
    # + outras Ã¡reas
}
3. IntegraÃ§Ã£o com IA Local
Consulta o modelo via API do Ollama com prompt otimizado para:

Linguagem humana e empÃ¡tica.
Respostas curtas (mÃ¡x. 2 frases).
Foco em conversÃ£o, nunca em automaÃ§Ã£o total.
4. GeraÃ§Ã£o de CTA (Call to Action)
Sempre termina com botÃ£o do WhatsApp, personalizado por Ã¡rea:

âŒ„
<a href="https://wa.me/551199887766?text=Quero+falar+sobre+divÃ³rcio">
  ğŸ“ Falar com especialista em Direito de FamÃ­lia
</a>
5. Redirecionamento Garantido
Mesmo em falhas da IA, o usuÃ¡rio Ã© direcionado ao WhatsApp.
Nenhum caso Ã© perdido.
ğŸ–¥ï¸ Frontend (index.html)
CaracterÃ­sticas TÃ©cnicas
Design responsivo com Bootstrap 5.3.
Tipografia elegante usando Google Fonts (Inter + Playfair Display).
Chatbot flutuante com animaÃ§Ã£o de pulsaÃ§Ã£o (CSS + JavaScript).
Totalmente acessÃ­vel e compatÃ­vel com dispositivos mÃ³veis.
Funcionalidades do Chat
Abre com clique no botÃ£o fixo (canto inferior direito).
Interface com mensagens do usuÃ¡rio (azul) e IA (cinza).
Mostra "digitando..." durante processamento.
Envio com Enter.
ComunicaÃ§Ã£o via fetch com o backend Flask.
ComunicaÃ§Ã£o com Backend
javascript

âŒ„
fetch('http://localhost:5000/chat', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ pergunta: msg })
})
ğŸ³ Docker Compose
docker-compose.yml
yaml


services:
  ollama:
    build: ./ollama-container
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

  web:
    build: ./web-container
    ports:
      - "5000:5000"
    depends_on:
      - ollama

volumes:
  ollama_data:
Recursos de OrquestraÃ§Ã£o
O serviÃ§o web inicia apenas apÃ³s ollama estar ativo.
Volume ollama_data garante persistÃªncia dos modelos.
Portas expostas:
5000: site e API Flask
11434: API do Ollama
ğŸš€ Como Executar
Clone o repositÃ³rio:
bash


1
git clone https://github.com/seu-usuario/dr-legal-advogados.git
Certifique-se de ter Docker e Docker Compose instalados.
Suba os serviÃ§os:
bash


1
docker-compose up --build
Acesse:
Site: http://localhost:5000
API da IA: http://localhost:11434
ğŸ’¡ EstratÃ©gia de ConversÃ£o
O sistema foi projetado para maximizar conversÃµes com:

Primeira consulta gratuita
Reduz barreira inicial
BotÃµes do WhatsApp
ConversÃ£o direta e imediata
CTAs personalizados por Ã¡rea
Maior relevÃ¢ncia e conversÃ£o
PlantÃ£o 24h
Atrai casos urgentes
Respostas curtas e humanas
Clareza e empatia
Redirecionamento garantido
Nenhum lead perdido

ğŸ›¡ï¸ Privacidade e Conformidade
Nenhum dado do usuÃ¡rio Ã© armazenado.
Toda IA roda localmente â€” sem envio a OpenAI, Gemini ou outras nuvens.
Sem cookies de rastreamento.
Totalmente compatÃ­vel com:
LGPD
CÃ³digo de Ã‰tica da Advocacia
Normas de proteÃ§Ã£o de dados sensÃ­veis
ğŸ§  Modelo de IA Utilizado
tinyllama:1.1b
Modelo leve, rÃ¡pido e eficiente.
Adequado para inferÃªncia em CPU.
Treinado em linguagem natural.
Adaptado via prompt para responder como um advogado empÃ¡tico e direto.
âœ… Futuramente pode ser substituÃ­do por modelos mais robustos como llama3, phi3 ou gemma para maior precisÃ£o. 

ğŸ“ˆ Fluxo de Atendimento
UsuÃ¡rio digita: "CaÃ­ em golpe no PIX, o que fazer?"
Sistema detecta palavra-chave â†’ "golpe", "PIX"
Classifica como: Direito do Consumidor
Gera resposta com CTA:
"Se vocÃª foi enganado no PIX, podemos tentar recuperar seu dinheiro.
ğŸ“ Falar com especialista em Consumidor " 
UsuÃ¡rio clica e conversa com advogado real.
ğŸ“Š BenefÃ­cios para EscritÃ³rios de Advocacia
Atendimento 24h
Captura leads fora do expediente
Triagem automatizada
Reduz tempo de anÃ¡lise inicial
Aumento de conversÃ£o
Mais contatos convertidos em clientes
ReduÃ§Ã£o de custos
Menos atendentes humanos necessÃ¡rios
Imagem moderna
Transmite inovaÃ§Ã£o e confianÃ§a

ğŸ“ Contato
Este projeto foi desenvolvido para escritÃ³rios de advocacia que desejam modernizar seu atendimento com tecnologia segura e eficaz.

Entre em contato para implantaÃ§Ã£o personalizada:

ğŸ“§ contato@drlegal.com.br
ğŸ“ (11) 99887-7766

ğŸ“„ LicenÃ§a
Este projeto Ã© fornecido como exemplo educacional e de referÃªncia.
VocÃª tem permissÃ£o para:

Adaptar para uso comercial
Personalizar para seu escritÃ³rio
Distribuir com atribuiÃ§Ã£o
NÃ£o inclui suporte oficial. 

Dr. Legal & Advogados â€“ JustiÃ§a AcessÃ­vel, com Tecnologia e Humanidade. âš–ï¸ğŸ’™ 